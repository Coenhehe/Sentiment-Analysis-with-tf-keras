{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Sentiment Analysis of online comments*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels:\n",
      " - defaults\n",
      " - conda-forge\n",
      "Platform: osx-arm64\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: failed\n",
      "\n",
      "PackagesNotFoundError: The following packages are not available from current channels:\n",
      "\n",
      "  - sklearn\n",
      "\n",
      "Current channels:\n",
      "\n",
      "  - defaults\n",
      "  - https://conda.anaconda.org/conda-forge/noarch\n",
      "  - https://conda.anaconda.org/conda-forge/osx-arm64\n",
      "\n",
      "To search for alternate channels that may provide the conda package you're\n",
      "looking for, navigate to\n",
      "\n",
      "    https://anaconda.org\n",
      "\n",
      "and use the search bar at the top of the page.\n",
      "\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%conda install pandas numpy tensorflow sklearn keras nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/coen/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/coen/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import libs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras.api._v2.keras as keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "#packages from nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read and format the csv in pandas\n",
    "df = pd.read_csv('training.1600000.processed.noemoticon.csv', encoding='latin-1', names=[\"sentiment\", \"ids\", \"date\", \"flag\", \"user\", \"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599995</th>\n",
       "      <td>4</td>\n",
       "      <td>Just woke up. Having no school is the best fee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599996</th>\n",
       "      <td>4</td>\n",
       "      <td>TheWDB.com - Very cool to hear old Walt interv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599997</th>\n",
       "      <td>4</td>\n",
       "      <td>Are you ready for your MoJo Makeover? Ask me f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599998</th>\n",
       "      <td>4</td>\n",
       "      <td>Happy 38th Birthday to my boo of alll time!!! ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599999</th>\n",
       "      <td>4</td>\n",
       "      <td>happy #charitytuesday @theNSPCC @SparksCharity...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1600000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sentiment                                               text\n",
       "0                0  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
       "1                0  is upset that he can't update his Facebook by ...\n",
       "2                0  @Kenichan I dived many times for the ball. Man...\n",
       "3                0    my whole body feels itchy and like its on fire \n",
       "4                0  @nationwideclass no, it's not behaving at all....\n",
       "...            ...                                                ...\n",
       "1599995          4  Just woke up. Having no school is the best fee...\n",
       "1599996          4  TheWDB.com - Very cool to hear old Walt interv...\n",
       "1599997          4  Are you ready for your MoJo Makeover? Ask me f...\n",
       "1599998          4  Happy 38th Birthday to my boo of alll time!!! ...\n",
       "1599999          4  happy #charitytuesday @theNSPCC @SparksCharity...\n",
       "\n",
       "[1600000 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#removing unneeded columns\n",
    "df.drop('ids', inplace=True, axis=1)\n",
    "df.drop('date', inplace=True, axis=1)\n",
    "df.drop('flag', inplace=True, axis=1)\n",
    "df.drop('user', inplace=True, axis=1)\n",
    "\n",
    "#check to make sure only 'sentiments' and 'text' columns remain\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          switchfoot httptwitpiccom2y1zl  awww thats a b...\n",
       "1          is upset that he cant update his facebook by t...\n",
       "2          kenichan i dived many times for the ball manag...\n",
       "3            my whole body feels itchy and like its on fire \n",
       "4          nationwideclass no its not behaving at all im ...\n",
       "                                 ...                        \n",
       "1599995    just woke up having no school is the best feel...\n",
       "1599996    thewdbcom  very cool to hear old walt intervie...\n",
       "1599997    are you ready for your mojo makeover ask me fo...\n",
       "1599998    happy 38th birthday to my boo of alll time tup...\n",
       "1599999    happy charitytuesday thenspcc sparkscharity sp...\n",
       "Name: text, Length: 1581466, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cleaning text\n",
    "def caydranisabum():\n",
    "    df.dropna(subset=['text'], inplace=True) #drop missing values\n",
    "    df.drop_duplicates(subset=['text'], inplace=True) #drop duplicates\n",
    "    df['text'] = df['text'].str.lower().str.replace('[^\\w\\s]', '', regex=True) #convert all chars to lowercase\n",
    "\n",
    "caydranisabum()\n",
    "df['text']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenisation of tweets using nltk\n",
    "df['tokens'] = df['text'].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          [switchfoot, httptwitpiccom2y1zl, awww, thats,...\n",
       "1          [upset, cant, update, facebook, texting, might...\n",
       "2          [kenichan, dived, many, times, ball, managed, ...\n",
       "3                    [whole, body, feels, itchy, like, fire]\n",
       "4            [nationwideclass, behaving, im, mad, cant, see]\n",
       "                                 ...                        \n",
       "1599995                  [woke, school, best, feeling, ever]\n",
       "1599996    [thewdbcom, cool, hear, old, walt, interviews,...\n",
       "1599997                [ready, mojo, makeover, ask, details]\n",
       "1599998    [happy, 38th, birthday, boo, alll, time, tupac...\n",
       "1599999    [happy, charitytuesday, thenspcc, sparkscharit...\n",
       "Name: tokens, Length: 1581466, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#removing stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "df['tokens'] = df['tokens'].apply(lambda x: [word for word in x if word not in stop_words])\n",
    "\n",
    "df['tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          [switchfoot, httptwitpiccom2y1zl, awww, that, ...\n",
       "1          [upset, cant, updat, facebook, text, might, cr...\n",
       "2          [kenichan, dive, mani, time, ball, manag, save...\n",
       "3                     [whole, bodi, feel, itchi, like, fire]\n",
       "4               [nationwideclass, behav, im, mad, cant, see]\n",
       "                                 ...                        \n",
       "1599995                     [woke, school, best, feel, ever]\n",
       "1599996    [thewdbcom, cool, hear, old, walt, interview, ...\n",
       "1599997                   [readi, mojo, makeov, ask, detail]\n",
       "1599998    [happi, 38th, birthday, boo, alll, time, tupac...\n",
       "1599999    [happi, charitytuesday, thenspcc, sparkschar, ...\n",
       "Name: tokens, Length: 1581466, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stemming\n",
    "stemmer = PorterStemmer()\n",
    "df['tokens'] = df['tokens'].apply(lambda x: [stemmer.stem(word) for word in x])\n",
    "\n",
    "df['tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>switchfoot httptwitpiccom2y1zl  awww thats a b...</td>\n",
       "      <td>[switchfoot, httptwitpiccom2y1zl, awww, that, ...</td>\n",
       "      <td>switchfoot httptwitpiccom2y1zl awww that bumme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he cant update his facebook by t...</td>\n",
       "      <td>[upset, cant, updat, facebook, text, might, cr...</td>\n",
       "      <td>upset cant updat facebook text might cri resul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>kenichan i dived many times for the ball manag...</td>\n",
       "      <td>[kenichan, dive, mani, time, ball, manag, save...</td>\n",
       "      <td>kenichan dive mani time ball manag save 50 res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>[whole, bodi, feel, itchi, like, fire]</td>\n",
       "      <td>whole bodi feel itchi like fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>nationwideclass no its not behaving at all im ...</td>\n",
       "      <td>[nationwideclass, behav, im, mad, cant, see]</td>\n",
       "      <td>nationwideclass behav im mad cant see</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599995</th>\n",
       "      <td>4</td>\n",
       "      <td>just woke up having no school is the best feel...</td>\n",
       "      <td>[woke, school, best, feel, ever]</td>\n",
       "      <td>woke school best feel ever</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599996</th>\n",
       "      <td>4</td>\n",
       "      <td>thewdbcom  very cool to hear old walt intervie...</td>\n",
       "      <td>[thewdbcom, cool, hear, old, walt, interview, ...</td>\n",
       "      <td>thewdbcom cool hear old walt interview Ã¢ httpb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599997</th>\n",
       "      <td>4</td>\n",
       "      <td>are you ready for your mojo makeover ask me fo...</td>\n",
       "      <td>[readi, mojo, makeov, ask, detail]</td>\n",
       "      <td>readi mojo makeov ask detail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599998</th>\n",
       "      <td>4</td>\n",
       "      <td>happy 38th birthday to my boo of alll time tup...</td>\n",
       "      <td>[happi, 38th, birthday, boo, alll, time, tupac...</td>\n",
       "      <td>happi 38th birthday boo alll time tupac amaru ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599999</th>\n",
       "      <td>4</td>\n",
       "      <td>happy charitytuesday thenspcc sparkscharity sp...</td>\n",
       "      <td>[happi, charitytuesday, thenspcc, sparkschar, ...</td>\n",
       "      <td>happi charitytuesday thenspcc sparkschar speak...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1581466 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sentiment                                               text  \\\n",
       "0                0  switchfoot httptwitpiccom2y1zl  awww thats a b...   \n",
       "1                0  is upset that he cant update his facebook by t...   \n",
       "2                0  kenichan i dived many times for the ball manag...   \n",
       "3                0    my whole body feels itchy and like its on fire    \n",
       "4                0  nationwideclass no its not behaving at all im ...   \n",
       "...            ...                                                ...   \n",
       "1599995          4  just woke up having no school is the best feel...   \n",
       "1599996          4  thewdbcom  very cool to hear old walt intervie...   \n",
       "1599997          4  are you ready for your mojo makeover ask me fo...   \n",
       "1599998          4  happy 38th birthday to my boo of alll time tup...   \n",
       "1599999          4  happy charitytuesday thenspcc sparkscharity sp...   \n",
       "\n",
       "                                                    tokens  \\\n",
       "0        [switchfoot, httptwitpiccom2y1zl, awww, that, ...   \n",
       "1        [upset, cant, updat, facebook, text, might, cr...   \n",
       "2        [kenichan, dive, mani, time, ball, manag, save...   \n",
       "3                   [whole, bodi, feel, itchi, like, fire]   \n",
       "4             [nationwideclass, behav, im, mad, cant, see]   \n",
       "...                                                    ...   \n",
       "1599995                   [woke, school, best, feel, ever]   \n",
       "1599996  [thewdbcom, cool, hear, old, walt, interview, ...   \n",
       "1599997                 [readi, mojo, makeov, ask, detail]   \n",
       "1599998  [happi, 38th, birthday, boo, alll, time, tupac...   \n",
       "1599999  [happi, charitytuesday, thenspcc, sparkschar, ...   \n",
       "\n",
       "                                              cleaned_text  \n",
       "0        switchfoot httptwitpiccom2y1zl awww that bumme...  \n",
       "1        upset cant updat facebook text might cri resul...  \n",
       "2        kenichan dive mani time ball manag save 50 res...  \n",
       "3                          whole bodi feel itchi like fire  \n",
       "4                    nationwideclass behav im mad cant see  \n",
       "...                                                    ...  \n",
       "1599995                         woke school best feel ever  \n",
       "1599996  thewdbcom cool hear old walt interview Ã¢ httpb...  \n",
       "1599997                       readi mojo makeov ask detail  \n",
       "1599998  happi 38th birthday boo alll time tupac amaru ...  \n",
       "1599999  happi charitytuesday thenspcc sparkschar speak...  \n",
       "\n",
       "[1581466 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['cleaned_text'] = df['tokens'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>switchfoot httptwitpiccom2y1zl awww that bumme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>upset cant updat facebook text might cri resul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>kenichan dive mani time ball manag save 50 res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>whole bodi feel itchi like fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>nationwideclass behav im mad cant see</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599995</th>\n",
       "      <td>4</td>\n",
       "      <td>woke school best feel ever</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599996</th>\n",
       "      <td>4</td>\n",
       "      <td>thewdbcom cool hear old walt interview Ã¢ httpb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599997</th>\n",
       "      <td>4</td>\n",
       "      <td>readi mojo makeov ask detail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599998</th>\n",
       "      <td>4</td>\n",
       "      <td>happi 38th birthday boo alll time tupac amaru ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599999</th>\n",
       "      <td>4</td>\n",
       "      <td>happi charitytuesday thenspcc sparkschar speak...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1581466 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sentiment                                       cleaned_text\n",
       "0                0  switchfoot httptwitpiccom2y1zl awww that bumme...\n",
       "1                0  upset cant updat facebook text might cri resul...\n",
       "2                0  kenichan dive mani time ball manag save 50 res...\n",
       "3                0                    whole bodi feel itchi like fire\n",
       "4                0              nationwideclass behav im mad cant see\n",
       "...            ...                                                ...\n",
       "1599995          4                         woke school best feel ever\n",
       "1599996          4  thewdbcom cool hear old walt interview Ã¢ httpb...\n",
       "1599997          4                       readi mojo makeov ask detail\n",
       "1599998          4  happi 38th birthday boo alll time tupac amaru ...\n",
       "1599999          4  happi charitytuesday thenspcc sparkschar speak...\n",
       "\n",
       "[1581466 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove columns\n",
    "df.drop('text', inplace=True, axis=1)\n",
    "df.drop('tokens', inplace=True, axis=1)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaned text ['switchfoot httptwitpiccom2y1zl awww that bummer shoulda got david carr third day'\n",
      " 'upset cant updat facebook text might cri result school today also blah'\n",
      " 'kenichan dive mani time ball manag save 50 rest go bound' ...\n",
      " 'readi mojo makeov ask detail'\n",
      " 'happi 38th birthday boo alll time tupac amaru shakur'\n",
      " 'happi charitytuesday thenspcc sparkschar speakinguph4h']\n",
      "labels [0 0 0 ... 4 4 4]\n"
     ]
    }
   ],
   "source": [
    "#csv to numpy arr\n",
    "texts = df['cleaned_text'].values\n",
    "labels = df['sentiment'].values\n",
    "\n",
    "print('cleaned text',texts)\n",
    "print('labels',labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA IS READY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " ...\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "#convert to bin\n",
    "from keras.utils import to_categorical\n",
    "labels = to_categorical(labels // 4, num_classes=2)\n",
    "\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 20000  #num ceil\n",
    "max_len = 100  #len ceil\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make len same\n",
    "data = pad_sequences(sequences, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=max_words, output_dim=128, input_length=max_len),\n",
    "    tf.keras.layers.Conv1D(128, 5, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling1D(pool_size=5),\n",
    "    tf.keras.layers.LSTM(128),\n",
    "    tf.keras.layers.Dense(2, activation='softmax')  # Change to 2 output units for 2 classes\n",
    "])\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training (10 epochs can increase)\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('sentiment_analysis_model_2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss n accuracy\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test Loss: {loss}')\n",
    "print(f'Test Accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentimentanalysis = tf.keras.models.load_model('sentiment_analysis_model.h5')\n",
    "\n",
    "sentimentanalysis.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(sentence):\n",
    "    #preprocess sentence\n",
    "    sentence = sentence.lower()\n",
    "    tokens = word_tokenize(sentence)\n",
    "    tokens = [stemmer.stem(word) for word in tokens if word not in stop_words]\n",
    "    cleaned_sentence = ' '.join(tokens)\n",
    "    \n",
    "    sequence = tokenizer.texts_to_sequences([cleaned_sentence])\n",
    "    padded_sequence = pad_sequences(sequence, maxlen=max_len)\n",
    "    \n",
    "    #predict\n",
    "    prediction = model.predict(padded_sequence, verbose=0)\n",
    "    sentiment_class = np.argmax(prediction)\n",
    "\n",
    "    #sent to label\n",
    "    sentiment_map = {0: 0, 1: 4}\n",
    "    if sentiment_map[sentiment_class] == 0:\n",
    "        return False\n",
    "    elif sentiment_map[sentiment_class] == 4:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = input('Comment: ')\n",
    "\n",
    "print(tmp)\n",
    "\n",
    "tmp2 = predict_sentiment(tmp)\n",
    "\n",
    "\n",
    "if tmp2 == True:\n",
    "    print('This comment has a positive sentiment.')\n",
    "elif tmp2 == False:\n",
    "    print('This comment has a negative sentiment.')\n",
    "\n",
    "print('')\n",
    "\n",
    "if len(tmp.split()) < 10:\n",
    "    print('Your sentence is ', len(tmp.split()), ' words, it is a short sentence. To get an accurate analysis, please make your sentence at least', 10-len(tmp.split()), ' words longer.')\n",
    "else:\n",
    "    print('Your sentence is ', len(tmp.split()), ' words long. The result should be accurate.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save and use the saved h5 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 100, 128)          2560000   \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 96, 128)           82048     \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (None, 19, 128)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 128)               131584    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,773,890\n",
      "Trainable params: 2,773,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "save_model = tf.keras.models.load_model('sentiment_analysis_model.h5')\n",
    "\n",
    "save_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment_save(sentence):\n",
    "    #preprocess sentence\n",
    "    sentence = sentence.lower()\n",
    "    tokens = word_tokenize(sentence)\n",
    "    tokens = [stemmer.stem(word) for word in tokens if word not in stop_words]\n",
    "    cleaned_sentence = ' '.join(tokens)\n",
    "    \n",
    "    sequence = tokenizer.texts_to_sequences([cleaned_sentence])\n",
    "    padded_sequence = pad_sequences(sequence, maxlen=max_len)\n",
    "    \n",
    "    #predict\n",
    "    prediction = save_model.predict(padded_sequence, verbose=0)\n",
    "    sentiment_class = np.argmax(prediction)\n",
    "\n",
    "    #sent to label\n",
    "    sentiment_map = {0: 0, 1: 4}\n",
    "    if sentiment_map[sentiment_class] == 0:\n",
    "        return False\n",
    "    elif sentiment_map[sentiment_class] == 4:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rizz\n",
      "\n",
      "This comment has a positive sentiment.\n",
      "\n",
      "Your sentence is  1  words, it is a short sentence. To get an accurate analysis, please make your sentence at least 9  words longer.\n"
     ]
    }
   ],
   "source": [
    "tmp = input('Comment: ')\n",
    "\n",
    "print(tmp)\n",
    "print('')\n",
    "\n",
    "tmp2 = predict_sentiment_save(tmp)\n",
    "\n",
    "\n",
    "if tmp2 == True:\n",
    "    print('This comment has a positive sentiment.')\n",
    "elif tmp2 == False:\n",
    "    print('This comment has a negative sentiment.')\n",
    "\n",
    "print('')\n",
    "\n",
    "if len(tmp.split()) < 10:\n",
    "    print('Your sentence is ', len(tmp.split()), ' words, it is a short sentence. To get an accurate analysis, please make your sentence at least', 10-len(tmp.split()), ' words longer.')\n",
    "else:\n",
    "    print('Your sentence is ', len(tmp.split()), ' words long. The result should be accurate.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
